{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Law of Iterative Logarithms and the Quasi-MLE Approximation\n",
    "The log-likelihood function corresponding to $n$ i.i.d random variables $x_1,\\dots,x_n$ from an unknown distribution $f^*$ is calculated in the following manner:\n",
    "$$L(\\theta) = \\sum_{i=1}^{n}\\log f(x_i|\\theta),$$\n",
    "where $f(x|\\theta)$ is a parametric density function designed to represent $f^*$ using a vector parameter $\\theta$. \n",
    "\n",
    "Using $L(\\theta)$, we can estimate the quasi-maximum likelihood estimate $\\hat{\\theta}$ of the best $\\theta^*$ for which $f(x|\\theta^*)=g(x)$ (i.e., $g(.)$ is feasible). We use the term \"quasi\" to show that $L(\\theta)$ is a function of $n$ and we further assume that for large enough $n$, the quasi-MLE is equal to the MLE. In this short note, we would like to show that under reasonable statistical assumptions on $g(.)$, the Quasi-MLE approaches the $L(\\theta^*)$ with a bias term of order $O(\\log\\log n)$. Derivations here are due to [1], which provides a more thorough description. \n",
    "\n",
    "Objective:   \n",
    "$$L(\\hat{\\theta}) - L(\\theta^*) = O(\\log\\log n)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Reasonable\" Stochastic Assumptions:\n",
    "\n",
    "We mentioned reasonable assumptions earlier. Briefly, these assumptions are:\n",
    "- $g(.)$ is feasible via $f(.|\\theta)$, for $\\theta=\\theta^*$. \n",
    "- $\\log f(x|\\theta)$ is a well-behaved function of $\\theta$. That is, it is differentiable and continuous. \n",
    "- The second-order derivative of $\\log f(x|\\theta)$ exists and is positive definite. \n",
    "- $\\lim_{n\\rightarrow\\infty} P[\\hat{\\theta}=\\theta^*]=1$\n",
    "- The third-order derivative of $\\log f(x|\\theta)$ is negligible. \n",
    "\n",
    "These are all reasonable in a sense that they are satisfied by many common families of distributions such as the exponential family. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof \n",
    "We start from the Taylor series expansion of $\\frac{\\partial L(\\hat{\\theta})}{\\partial\\theta}$ around $\\theta^*$:\n",
    "\n",
    "$$\\frac{\\partial L(\\hat{\\theta})}{\\partial\\theta} = \\frac{\\partial L(\\hat{\\theta})}{\\partial\\theta^*} - W(\\theta^*)(\\hat{\\theta}-\\theta^*) + H.O.T$$\n",
    "where $W(\\theta) = -\\frac{\\partial^2 }{\\partial\\theta\\partial\\theta^\\top}L(\\theta)$ and H.O.T corresponds to the third-order derivative of $L(\\theta)$. \n",
    "\n",
    "Since $\\hat{\\theta}$ maximizes $L(\\theta)$, by definition maximizes the quasi-ML $\\frac{\\partial }{\\partial\\theta}L(\\hat{\\theta}) = 0$. \n",
    "\n",
    "Also, since $\\theta^*$ maximizes the log-likelihood, we have $\\frac{\\partial }{\\partial\\theta}E_{g}[\\log f(x|{\\theta})] = 0$, where $E_{g}$ is expectation with respect to $g(x)$. The fact that $\\frac{\\partial }{\\partial\\theta}E_{g}[\\log f(x|{\\theta^*})] = 0$ means $E_{g}[\\frac{\\partial }{\\partial\\theta}\\log f(x|{\\theta^*})] = 0$ and there $\\log f(x|\\theta^*)$ is a zero-mean random variable. Using the third assumption, $\\log f(x|\\theta)$ also has finite variance, therefore the random variable $L(\\theta^*)$ which represents sum of samples from $\\log f(x|\\theta^*)$ obeys the [Law of Iterative Logarithms](https://en.wikipedia.org/wiki/Law_of_the_iterated_logarithm) [2]. Therefore, \n",
    "for large $n$\n",
    "$$\\frac{\\partial}{\\partial\\theta} L(\\theta^*) = O(\\sqrt{n\\log\\log n})$$\n",
    "\n",
    "Using this result and $\\frac{\\partial }{\\partial\\theta}L(\\hat{\\theta}) = 0$ and dividing the Taylor series expansion by $n$, we have:\n",
    "\n",
    "$$\\frac{1}{n}\\frac{\\partial L(\\hat{\\theta})}{\\partial\\theta^*} - \\frac{1}{n}W(\\theta^*)(\\hat{\\theta}-\\theta^*) + \\frac{1}{n}H.O.T = 0$$\n",
    "\n",
    "NOTE: Let's accept that $\\frac{1}{n}H.O.T = O(1)(\\hat{\\theta} - \\theta^*)$, which is somewhat justified by the last assumption from the previous section. Then we have:\n",
    "\n",
    "$$\\frac{1}{n}O(\\sqrt(n\\log\\log n)) - W(\\theta^*)(\\hat{\\theta}-\\theta^*) + O(1)(\\hat{\\theta} - \\theta_g) = 0$$\n",
    "$$\\Rightarrow  (\\hat{\\theta}-\\theta^*) = [O(1) + W(\\theta^*)]^{-1}O(\\sqrt{n\\log\\log n})/n$$\n",
    "\n",
    "From the third assumption, $[O(1) + W(\\theta^*)]$ is invertible and from the second assumption it's depency on $n$ vanishes for large $n$. Then\n",
    "\n",
    "$$(\\hat{\\theta}-\\theta^*) = O(\\sqrt{\\frac{\\log\\log n}{n}})$$\n",
    "\n",
    "Finally, we can use the second order Taylor series expansion of $L(\\hat{\\theta})$ around $\\theta^*$:\n",
    "\n",
    "$$L(\\hat{\\theta}) = L(\\theta^*) + (\\hat{\\theta} - \\theta^*)^{\\top}\\frac{\\partial L(\\theta^*)}{\\partial\\theta} + (\\hat{\\theta} - \\theta^*)^{\\top}\\frac{\\partial^2 L(\\theta^*)}{\\partial\\theta\\partial\\theta^\\top}(\\hat{\\theta} - \\theta^*)$$\n",
    "\n",
    "From before, \n",
    "$$(\\hat{\\theta} - \\theta^*)^{\\top}\\frac{\\partial L(\\theta^*)}{\\partial\\theta} = O(\\sqrt{\\frac{\\log\\log n}{n}})O(\\sqrt{n\\log\\log n}) = O(\\log\\log n)$$ \n",
    "and the last term is negligible because it has two multiplied $(\\hat{\\theta} - \\theta^*)$ and the Hessian is finite according to the $3^{rd}$ assumption. Therefore:\n",
    "\n",
    "$$L(\\hat{\\theta}) = L(\\theta^*) + O(\\log\\log n) \\blacksquare$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "[1] Nishii, R. (1988). Maximum likelihood principle and model selection when the true model is unspecified. Journal of Multivariate analysis, 27(2), 392-403.\n",
    "\n",
    "[2] Kolmogoroff, A. (1929). Ãœber das Gesetz des iterierten Logarithmus. Mathematische Annalen, 101(1), 126-135."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
